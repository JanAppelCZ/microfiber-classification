{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from mrmr import mrmr_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "matplotlib: 3.10.8\n",
      "mrmr      : 0.2.8\n",
      "numpy     : 2.3.5\n",
      "pandas    : 2.3.3\n",
      "sklearn   : 1.8.0\n",
      "tensorflow: 2.20.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_Znorm=pd.read_csv('data/x_train_Znorm.csv')\n",
    "x_val_Znorm=pd.read_csv('data/x_val_Znorm.csv')\n",
    "y_train=pd.DataFrame(np.argmax(np.load('data/y_train.npy'),axis=1))\n",
    "y_val=pd.DataFrame(np.argmax(np.load('data/y_val.npy'),axis=1))\n",
    "\n",
    "# Calculation of class weights based on training data\n",
    "classis = np.unique(y_train)\n",
    "weight_classis = compute_class_weight(class_weight='balanced', classes=classis, y=y_train)\n",
    "weight_classis_dict = dict(zip(classis, weight_classis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = []\n",
    "svm_scores = []\n",
    "knn_scores = []\n",
    "gb_scores = []\n",
    "lr_scores = []\n",
    "nb_scores = []\n",
    "\n",
    "#Gaussian Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(x_train_Znorm, y_train)\n",
    "report_dict = classification_report(y_val, nb_model.predict(x_val_Znorm), output_dict=True)\n",
    "nb_scores = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "\n",
    "#Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=5000,max_depth=None,class_weight=weight_classis_dict,random_state=5000,n_jobs=-1)\n",
    "rf_model.fit(x_train_Znorm, y_train)\n",
    "report_dict = classification_report(y_val, rf_model.predict(x_val_Znorm), output_dict=True)\n",
    "rf_scores = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "\n",
    "#K nearest Neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5,weights='distance',n_jobs=-1)\n",
    "knn_model.fit(x_train_Znorm, y_train)\n",
    "report_dict = classification_report(y_val, knn_model.predict(x_val_Znorm), output_dict=True)\n",
    "knn_scores = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "\n",
    "#Support Vector Machine\n",
    "svm_model = SVC(kernel='rbf',class_weight=weight_classis_dict,probability=True,random_state=42)\n",
    "svm_model.fit(x_train_Znorm, y_train)\n",
    "report_dict = classification_report(y_val, svm_model.predict(x_val_Znorm), output_dict=True)\n",
    "svm_scores = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "\n",
    "#Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=300,learning_rate=0.1,max_depth=100,random_state=42)\n",
    "gb_model.fit(x_train_Znorm, y_train)\n",
    "report_dict = classification_report(y_val, gb_model.predict(x_val_Znorm), output_dict=True)\n",
    "gb_scores = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "\n",
    "#Logistic Regression\n",
    "lr_model = LogisticRegression(solver='lbfgs',class_weight=weight_classis_dict,max_iter=1000,random_state=42,n_jobs=-1)\n",
    "lr_model.fit(x_train_Znorm, y_train)\n",
    "report_dict = classification_report(y_val, lr_model.predict(x_val_Znorm), output_dict=True)\n",
    "lr_scores = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML model scores without feature selection:\n",
      "------------------------------------------------\n",
      "Model                   Accuracy,  Precision,       Recall,       F1-score\n",
      "Gaussian Naive Bayes    acc=0.800, Precision=0.814, Recall=0.801, F1=0.800\n",
      "Random Forest           acc=0.833, Precision=0.839, Recall=0.829, F1=0.829\n",
      "K nearest Neighbors     acc=0.867, Precision=0.876, Recall=0.861, F1=0.855\n",
      "Support Vector Machine  acc=0.883, Precision=0.881, Recall=0.881, F1=0.879\n",
      "Gradient Boosting       acc=0.883, Precision=0.872, Recall=0.874, F1=0.872\n",
      "Logistic Regression     acc=0.900, Precision=0.909, Recall=0.899, F1=0.899\n"
     ]
    }
   ],
   "source": [
    "print(\"ML model scores without feature selection:\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Model                   Accuracy,  Precision,       Recall,       F1-score\")\n",
    "print(f'Gaussian Naive Bayes    acc={nb_scores[0]:.3f}, Precision={nb_scores[1]:.3f}, Recall={nb_scores[2]:.3f}, F1={nb_scores[3]:.3f}')\n",
    "print(f'Random Forest           acc={rf_scores[0]:.3f}, Precision={rf_scores[1]:.3f}, Recall={rf_scores[2]:.3f}, F1={rf_scores[3]:.3f}')\n",
    "print(f'K nearest Neighbors     acc={knn_scores[0]:.3f}, Precision={knn_scores[1]:.3f}, Recall={knn_scores[2]:.3f}, F1={knn_scores[3]:.3f}')\n",
    "print(f'Support Vector Machine  acc={svm_scores[0]:.3f}, Precision={svm_scores[1]:.3f}, Recall={svm_scores[2]:.3f}, F1={svm_scores[3]:.3f}')\n",
    "print(f'Gradient Boosting       acc={gb_scores[0]:.3f}, Precision={gb_scores[1]:.3f}, Recall={gb_scores[2]:.3f}, F1={gb_scores[3]:.3f}')\n",
    "print(f'Logistic Regression     acc={lr_scores[0]:.3f}, Precision={lr_scores[1]:.3f}, Recall={lr_scores[2]:.3f}, F1={lr_scores[3]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with feature selection mRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:02<00:00, 28.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=10 done\n",
      "K=11 done\n",
      "K=12 done\n",
      "K=13 done\n",
      "K=14 done\n",
      "K=15 done\n",
      "K=16 done\n",
      "K=17 done\n",
      "K=18 done\n",
      "K=19 done\n",
      "K=20 done\n",
      "K=21 done\n",
      "K=22 done\n",
      "K=23 done\n",
      "K=24 done\n",
      "K=25 done\n",
      "K=26 done\n",
      "K=27 done\n",
      "K=28 done\n",
      "K=29 done\n",
      "K=30 done\n",
      "K=31 done\n",
      "K=32 done\n",
      "K=33 done\n",
      "K=34 done\n",
      "K=35 done\n",
      "K=36 done\n",
      "K=37 done\n",
      "K=38 done\n",
      "K=39 done\n",
      "K=40 done\n",
      "K=41 done\n",
      "K=42 done\n",
      "K=43 done\n",
      "K=44 done\n",
      "K=45 done\n",
      "K=46 done\n",
      "K=47 done\n",
      "K=48 done\n",
      "K=49 done\n",
      "K=50 done\n",
      "K=51 done\n",
      "K=52 done\n",
      "K=53 done\n",
      "K=54 done\n",
      "K=55 done\n",
      "K=56 done\n",
      "K=57 done\n",
      "K=58 done\n",
      "K=59 done\n",
      "K=60 done\n",
      "K=61 done\n",
      "K=62 done\n",
      "K=63 done\n",
      "K=64 done\n",
      "K=65 done\n",
      "K=66 done\n",
      "K=67 done\n",
      "K=68 done\n",
      "K=69 done\n",
      "K=70 done\n",
      "K=71 done\n"
     ]
    }
   ],
   "source": [
    "selected = mrmr_classif(X=x_train_Znorm, y=y_train, K=72)\n",
    "K_values = range(10, 72,1)\n",
    "rf_scores = []\n",
    "svm_scores = []\n",
    "knn_scores = []\n",
    "gb_scores = []\n",
    "lr_scores = []\n",
    "nb_scores = []\n",
    "\n",
    "for K in K_values:\n",
    "    x_train_sel = x_train_Znorm[selected[:K]]\n",
    "    x_val_sel = x_val_Znorm[selected[:K]]\n",
    "\n",
    "    #Gaussian Naive Bayes\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(x_train_sel, y_train)\n",
    "    report_dict = classification_report(y_val, nb_model.predict(x_val_sel), output_dict=True)\n",
    "    report = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "    nb_scores.append(report)\n",
    "\n",
    "    #Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=5000,max_depth=None,class_weight=weight_classis_dict,random_state=5000,n_jobs=-1)\n",
    "    rf_model.fit(x_train_sel, y_train)\n",
    "    report_dict = classification_report(y_val, rf_model.predict(x_val_sel), output_dict=True)\n",
    "    report = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "    rf_scores.append(report)\n",
    "\n",
    "    #KNN\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5,weights='distance',n_jobs=-1)\n",
    "    knn_model.fit(x_train_sel, y_train)\n",
    "    report_dict = classification_report(y_val, knn_model.predict(x_val_sel), output_dict=True)\n",
    "    report = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "    knn_scores.append(report)\n",
    "\n",
    "    #SVM\n",
    "    svm_model = SVC(kernel='rbf',class_weight=weight_classis_dict,probability=True,random_state=42)\n",
    "    svm_model.fit(x_train_sel, y_train)\n",
    "    report_dict = classification_report(y_val, svm_model.predict(x_val_sel), output_dict=True)\n",
    "    report = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "    svm_scores.append(report)\n",
    "\n",
    "    #Gradient Boosting\n",
    "    gb_model = GradientBoostingClassifier(n_estimators=300,learning_rate=0.1,max_depth=100,random_state=42)\n",
    "    gb_model.fit(x_train_sel, y_train)\n",
    "    report_dict = classification_report(y_val, gb_model.predict(x_val_sel), output_dict=True)\n",
    "    report = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "    gb_scores.append(report)\n",
    "    \n",
    "    #Logistic Regression\n",
    "    lr_model = LogisticRegression(solver='lbfgs',class_weight=weight_classis_dict,max_iter=1000,random_state=42,n_jobs=-1)\n",
    "    lr_model.fit(x_train_sel, y_train)\n",
    "    report_dict = classification_report(y_val, lr_model.predict(x_val_sel), output_dict=True)\n",
    "    report = [report_dict['accuracy'],report_dict['macro avg']['precision'],report_dict['macro avg']['recall'],report_dict['macro avg']['f1-score']]\n",
    "    lr_scores.append(report)\n",
    "\n",
    "    print(f'K={K} done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = np.array(rf_scores)\n",
    "svm_scores = np.array(svm_scores)\n",
    "knn_scores = np.array(knn_scores)\n",
    "gb_scores = np.array(gb_scores)\n",
    "lr_scores = np.array(lr_scores)\n",
    "nb_scores = np.array(nb_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimální K: 58, NB acc=0.817, Precision=0.828, Recall=0.818, F1=0.815\n",
      "Optimální K: 34, RF acc=0.850, Precision=0.862, Recall=0.847, F1=0.849\n",
      "Optimální K: 39, KNN acc=0.900, Precision=0.906, Recall=0.896, F1=0.894\n",
      "Optimální K: 35, SVM acc=0.900, Precision=0.908, Recall=0.901, F1=0.900\n",
      "Optimální K: 56, GB acc=0.883, Precision=0.872, Recall=0.874, F1=0.872\n",
      "Optimální K: 40, LR acc=0.917, Precision=0.920, Recall=0.918, F1=0.916\n"
     ]
    }
   ],
   "source": [
    "print(f'Optimální K: {K_values[np.argmax(nb_scores[:,0])]}, NB acc={np.max(nb_scores[:,0]):.3f}, Precision={nb_scores[np.argmax(nb_scores[:,0]),1]:.3f}, Recall={nb_scores[np.argmax(nb_scores[:,0]),2]:.3f}, F1={nb_scores[np.argmax(nb_scores[:,0]),3]:.3f}')\n",
    "print(f'Optimální K: {K_values[np.argmax(rf_scores[:,0])]}, RF acc={np.max(rf_scores[:,0]):.3f}, Precision={rf_scores[np.argmax(rf_scores[:,0]),1]:.3f}, Recall={rf_scores[np.argmax(rf_scores[:,0]),2]:.3f}, F1={rf_scores[np.argmax(rf_scores[:,0]),3]:.3f}')\n",
    "print(f'Optimální K: {K_values[np.argmax(knn_scores[:,0])]}, KNN acc={np.max(knn_scores[:,0]):.3f}, Precision={knn_scores[np.argmax(knn_scores[:,0]),1]:.3f}, Recall={knn_scores[np.argmax(knn_scores[:,0]),2]:.3f}, F1={knn_scores[np.argmax(knn_scores[:,0]),3]:.3f}')\n",
    "print(f'Optimální K: {K_values[np.argmax(svm_scores[:,0])]}, SVM acc={np.max(svm_scores[:,0]):.3f}, Precision={svm_scores[np.argmax(svm_scores[:,0]),1]:.3f}, Recall={svm_scores[np.argmax(svm_scores[:,0]),2]:.3f}, F1={svm_scores[np.argmax(svm_scores[:,0]),3]:.3f}')\n",
    "print(f'Optimální K: {K_values[np.argmax(gb_scores[:,0])]}, GB acc={np.max(gb_scores[:,0]):.3f}, Precision={gb_scores[np.argmax(gb_scores[:,0]),1]:.3f}, Recall={gb_scores[np.argmax(gb_scores[:,0]),2]:.3f}, F1={gb_scores[np.argmax(gb_scores[:,0]),3]:.3f}')\n",
    "print(f'Optimální K: {K_values[np.argmax(lr_scores[:,0])]}, LR acc={np.max(lr_scores[:,0]):.3f}, Precision={lr_scores[np.argmax(lr_scores[:,0]),1]:.3f}, Recall={lr_scores[np.argmax(lr_scores[:,0]),2]:.3f}, F1={lr_scores[np.argmax(lr_scores[:,0]),3]:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "{featureselection}",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
