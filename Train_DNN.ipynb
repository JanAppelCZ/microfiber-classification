{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras import layers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras : 3.13.1\n",
      "numpy : 2.3.5\n",
      "pandas: 2.3.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_Znorm = pd.read_csv('data/x_train_Znorm.csv')\n",
    "x_val_Znorm = pd.read_csv('data/x_val_Znorm.csv')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "y_val = np.load('data/y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints:\n",
    "def create_model():\n",
    "    model=keras.Sequential([\n",
    "        layers.Input(shape=(72,)),    \n",
    "        layers.Dense(256, activation='relu',kernel_regularizer=regularizers.L1L2(l1=1e-3, l2=1e-2), bias_regularizer=regularizers.L2(1e-2),\n",
    "        activity_regularizer=regularizers.L2(1e-5)),\n",
    "        BatchNormalization(),\n",
    "        layers.Dropout(0.8),  \n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), bias_regularizer=regularizers.L2(1e-4),\n",
    "        activity_regularizer=regularizers.L2(1e-5)),\n",
    "        BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(6, activation='softmax')\n",
    "    ])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def class_w(y_train):\n",
    "    y_train=np.argmax(y_train, axis=1)\n",
    "    class_counts = Counter(y_train)\n",
    "    total_samples = len(y_train)\n",
    "    class_w = {cls: total_samples / (len(class_counts) * count) for cls, count in class_counts.items()}\n",
    "    return class_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "j=0\n",
    "acc=0.96\n",
    "acc_list=[]\n",
    "while i<100:\n",
    "    filepath=f'data/best_model_v2_{i}.keras'\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.98, patience=20, min_lr=0.0000001,mode='auto')\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint,reduce_lr]\n",
    "    cl_w = class_w(y_train)\n",
    "    history=create_model().fit(x_train_Znorm,y_train,batch_size=50,epochs=300,validation_data=(x_val_Znorm,y_val),callbacks=callbacks_list, class_weight=cl_w)\n",
    "    acc_list.append(max(history.history['val_categorical_accuracy']))\n",
    "    if max(history.history['val_categorical_accuracy'])>acc:\n",
    "        np.savez(f'data/history_v2_{i}.npz', \n",
    "         data=pd.DataFrame(history.history).to_numpy().astype(np.float32),\n",
    "         columns=list(pd.DataFrame(history.history).columns))\n",
    "        print(f'Model {i} done during {j} attempts')\n",
    "        i+=1\n",
    "    np.save('data/acc_list',acc_list)\n",
    "    j+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "{featureselection}",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
